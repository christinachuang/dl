{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Competition2 Report\n",
    "### Group 43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Student ID, name of each team member.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "107065511 莊筑鈞\n",
    "\n",
    "107062523 程薰瑩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "#if you have multiple GPU on the machine, choose only one to use on this notebook\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "#let the gpu allocates memory space dynamically\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.allow_growth = True\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "classes_name =  [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \n",
    "                 \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \n",
    "                 \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \n",
    "                 \"sheep\", \"sofa\", \"train\",\"tvmonitor\"]\n",
    "### DATASET LOADER ###\n",
    "class DatasetRunner:\n",
    "    \"\"\"\n",
    "    Load pascalVOC 2007 dataset and creates an input pipeline ready to be fed into a model.\n",
    "    - Reshapes images into 448 x 448\n",
    "    - converts [0 1] to [-1 1]\n",
    "    - shuffles the input\n",
    "    - builds batches\n",
    "    \"\"\"\n",
    "    def __init__(self, common_params, dataset_params, config): \n",
    "        self.width = common_params['image_size']\n",
    "        self.height = common_params['image_size']\n",
    "        self.batch_size = common_params['batch_size']\n",
    "        self.num_classes = common_params['num_classes']\n",
    "        self.data_path = dataset_params['path']\n",
    "        self.thread_num = dataset_params['thread_num']\n",
    "        self.image_dir = dataset_params['image_dir']\n",
    "        self.max_objects = common_params['max_objects_per_image']\n",
    "        self.graph = tf.Graph()\n",
    "        self.sess = tf.Session(graph=self.graph, config=config)\n",
    "        self.image_names = []\n",
    "        self.record_list = []\n",
    "        self.object_num_list = []\n",
    "        # filling the record_list\n",
    "        input_file = open(self.data_path, 'r')\n",
    "        for line in input_file:\n",
    "            line = line.strip()\n",
    "            ss = line.split(' ')\n",
    "            self.image_names.append(ss[0])\n",
    "            self.record_list.append([float(num) for num in ss[1:]])\n",
    "            self.object_num_list.append(min(len(self.record_list[-1])//5, self.max_objects))\n",
    "            if len(self.record_list[-1])<self.max_objects*5:\n",
    "                self.record_list[-1] = self.record_list[-1] +[float(0), float(0), float(0), float(0), float(0)]*\\\n",
    "                (self.max_objects-len(self.record_list[-1])//5)\n",
    "            elif len(self.record_list[-1])>self.max_objects*5:\n",
    "                self.record_list[-1] = self.record_list[-1][:self.max_objects*5]\n",
    "        self.build_train_data_tensor()\n",
    "          \n",
    "    def build_train_data_tensor(self):       \n",
    "        def data_generator(image_name, raw_labels, object_num):\n",
    "            image_file = tf.read_file(self.image_dir+image_name)\n",
    "            image = tf.image.decode_jpeg(image_file, channels=3)\n",
    "            h = tf.shape(image)[0]\n",
    "            w = tf.shape(image)[1]\n",
    "            width_rate = self.width * 1.0 / tf.cast(w, tf.float32) \n",
    "            height_rate = self.height * 1.0 / tf.cast(h, tf.float32)\n",
    "            image = tf.image.resize_images(image, size=[self.height,self.width])\n",
    "            image = image / 255 * 2 - 1\n",
    "            #image = tf.image.random_hue(image, max_delta=0.2)\n",
    "            #image = tf.image.random_contrast(image, lower=0.5, upper=1.5)\n",
    "            #image = tf.image.random_brightness(image, max_delta=32./255.)\n",
    "            #image = tf.image.random_saturation(image, lower=0.5, upper=1.5) \n",
    "            raw_labels = tf.cast(tf.reshape(raw_labels, [-1, 5]), tf.float32)\n",
    "            xmin = raw_labels[:, 0]\n",
    "            ymin = raw_labels[:, 1]\n",
    "            xmax = raw_labels[:, 2]\n",
    "            ymax = raw_labels[:, 3]\n",
    "            class_num = raw_labels[:, 4]\n",
    "            xcenter = (xmin + xmax) * 1.0 / 2.0 * width_rate\n",
    "            ycenter = (ymin + ymax) * 1.0 / 2.0 * height_rate\n",
    "            box_w = (xmax - xmin) * width_rate\n",
    "            box_h = (ymax - ymin) * height_rate\n",
    "            #th = random.random()\n",
    "            #if th > 0.5:\n",
    "            #    image = tf.image.flip_left_right(image)\n",
    "            #    xcenter = self.width - 1 - xcenter \n",
    "            labels = tf.stack([xcenter, ycenter, box_w, box_h, class_num], axis = 1)\n",
    "            return image, labels, tf.cast(object_num, tf.int32)\n",
    "            \n",
    "        with self.graph.as_default():\n",
    "            dataset = tf.data.Dataset.from_tensor_slices((self.image_names, \n",
    "                                                          np.array(self.record_list), \n",
    "                                                          np.array(self.object_num_list)))\n",
    "            #dataset = dataset.shuffle(len(self.record_list))\n",
    "            dataset = dataset.map(data_generator, num_parallel_calls = self.thread_num)\n",
    "            #dataset = dataset.batch(self.batch_size)\n",
    "            dataset = dataset.shuffle(len(self.record_list)) \n",
    "            dataset = dataset.batch(self.batch_size)\n",
    "            dataset = dataset.repeat()\n",
    "            self.iterator = tf.data.Iterator.from_structure(dataset.output_types)  \n",
    "            self.data_init_op = self.iterator.make_initializer(dataset)\n",
    "            self.sess.run(self.data_init_op)\n",
    "            self.iterate_op = self.iterator.get_next()\n",
    "            \n",
    "    def batch(self):\n",
    "        images, labels, objects_num = self.sess.run(self.iterate_op)\n",
    "        if objects_num.shape[0] < self.batch_size:\n",
    "            images, labels, objects_num = self.sess.run(self.iterate_op)\n",
    "        #images = images/255 * 2 - 1\n",
    "        return images, labels, objects_num\n",
    "        \n",
    "    def __del__(self):\n",
    "        self.close()\n",
    "\n",
    "    def close(self):\n",
    "        self.sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_def.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class YoloRunner(object):\n",
    "    def __init__(self, dataset, net, common_params, solver_params, pre_model=False):\n",
    "        #process params\n",
    "        self.learning_rate = float(solver_params['learning_rate'])\n",
    "        #self.decay_rate = float(solver_params['decay_rate'])\n",
    "        self.moment = float(solver_params['moment'])\n",
    "        self.batch_size = int(common_params['batch_size'])\n",
    "        self.height = int(common_params['image_size'])\n",
    "        self.width = int(common_params['image_size'])\n",
    "        self.max_objects = int(common_params['max_objects_per_image'])\n",
    "        self.train_dir = str(solver_params['train_dir'])\n",
    "        if pre_model:\n",
    "            self.pretrain_path = str(solver_params['pretrain_path'])\n",
    "        if not os.path.exists(self.train_dir):\n",
    "            os.makedirs(self.train_dir)\n",
    "        self.max_iterators = int(solver_params['max_iterators'])\n",
    "        #self.decay_step = int(solver_params['decay_step'])\n",
    "        self.print_frequency = int(solver_params['print_frequency'])\n",
    "        self.save_frequency = int(solver_params['save_frequency'])\n",
    "        self.dataset = dataset\n",
    "        self.net = net\n",
    "        self.construct_graph()\n",
    "\n",
    "    def _train(self):\n",
    "        \"\"\"Train model\n",
    "        Create an optimizer and apply to all trainable variables.\n",
    "        Args:\n",
    "          total_loss: Total loss from net.loss()\n",
    "          global_step: Integer Variable counting the number of training steps\n",
    "          processed\n",
    "        Returns:\n",
    "          train_op: op for training\n",
    "        \"\"\"\n",
    "        #opt = tf.train.MomentumOptimizer(self.learning_rate, self.moment)\n",
    "        #opt = tf.train.GradientDescentOptimizer(self.learning_rate)\n",
    "        self.update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        #print(update_ops)\n",
    "        #with tf.control_dependencies(self.update_ops):\n",
    "        #lr = tf.train.exponential_decay(self.learning_rate, self.global_step, self.decay_step, self.decay_rate, True)\n",
    "        opt = tf.train.AdamOptimizer(self.learning_rate)\n",
    "        grads = opt.compute_gradients(self.total_loss) #tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))\n",
    "        apply_gradient_op = opt.apply_gradients(grads, global_step=self.global_step)\n",
    "        return apply_gradient_op\n",
    "\n",
    "    def construct_graph(self):\n",
    "        self.global_step = tf.Variable(0, trainable=False)        \n",
    "        self.images = tf.placeholder(tf.float32, (None, self.height, self.width, 3))\n",
    "        self.labels = tf.placeholder(tf.float32, (None, self.max_objects, 5))\n",
    "        self.objects_num = tf.placeholder(tf.int32, (None))\n",
    "        self.predicts = self.net.inference(self.images)\n",
    "        self.total_loss, self.nilboy, self.losses = self.net.loss(self.predicts, self.labels, self.objects_num)\n",
    "        tf.summary.scalar('loss', self.total_loss)\n",
    "        self.train_op = self._train()\n",
    "\n",
    "    def run(self, config, pre_model=False):\n",
    "        #self.construct_graph()\n",
    "       # v_list = tf.trainable_varables() \n",
    "       # g_list = tf.global_variables()\n",
    "        #bn_moving_vars = [g for g in g_list if ('moving_mean' or 'moving_variance' or 'gamma' or 'beta') in g.name]\n",
    "        #bn_moving_vars += [g for g in g_list if 'moving_variance' in g.name]\n",
    "        #bn_moving_vars = [g for g in g_list if 'moving_mean' in g.name]\n",
    "        #bn_moving_vars += [g for g in g_list if 'moving_variance' in g.name]\n",
    "        #v_list += bn_moving_vars\n",
    "        #print(bn_moving_vars)\n",
    "        #self.net.trainable_collection.append(bn_moving_vars)\n",
    "        #saver = tf.train.Saver(v_list, write_version=tf.train.SaverDef.V2)\n",
    "        init =  tf.global_variables_initializer()\n",
    "        summary_op = tf.summary.merge_all()\n",
    "        sess = tf.Session(config = config)\n",
    "        sess.run(init)\n",
    "        #self.train_op = self._train()\n",
    "        v_list = tf.trainable_variables() \n",
    "        g_list = tf.global_variables()\n",
    "        #bn_moving_vars = [g for g in g_list if ('moving_mean' or 'moving_variance' or 'gamma' or 'beta') in g.name]\n",
    "        #bn_moving_vars += [g for g in g_list if 'moving_variance' in g.name]\n",
    "        bn_moving_vars = [g for g in g_list if 'moving_mean' in g.name]\n",
    "        bn_moving_vars += [g for g in g_list if 'moving_variance' in g.name]\n",
    "        v_list += bn_moving_vars\n",
    "        #print(bn_moving_vars)\n",
    "        #self.net.trainable_collection.append(bn_moving_vars)\n",
    "        saver = tf.train.Saver(self.net.trainable_collection, write_version=tf.train.SaverDef.V2)\n",
    "        #self.train_op = self._train()\n",
    "        if pre_model:\n",
    "            saver.restore(sess, self.pretrain_path)\n",
    "            print('Finish Loading Pre-trained model: %s' %self.pretrain_path)\n",
    "        summary_writer = tf.summary.FileWriter(self.train_dir, sess.graph)\n",
    "        for step in range(self.max_iterators):\n",
    "            start_time = time.time()\n",
    "            np_images, np_labels, np_objects_num = self.dataset.batch()\n",
    "            _, loss_value, losses, nilboy= sess.run([self.train_op, self.total_loss, self.losses, self.nilboy], \n",
    "                                            feed_dict={self.images: np_images, \n",
    "                                                       self.labels: np_labels,\n",
    "                                                       self.objects_num: np_objects_num})\n",
    "            duration = time.time() - start_time\n",
    "            assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\n",
    "            if step % self.print_frequency== 0:\n",
    "                num_examples_per_step = self.dataset.batch_size\n",
    "                examples_per_sec = num_examples_per_step / duration\n",
    "                sec_per_batch = float(duration)\n",
    "                format_str = ('step %d, loss = %.2f, cls_loss = %.2f, obj_loss = %.2f, nobj_loss = %.2f, coord_loss = %.2f (%.1f examples/sec; %.3f ' 'sec/batch)')\n",
    "                print (format_str % (step, loss_value, losses[0], losses[1], losses[2], losses[3], examples_per_sec, sec_per_batch))\n",
    "                sys.stdout.flush()\n",
    "            if step % self.print_frequency == 0:\n",
    "                summary_str = sess.run(summary_op, feed_dict={self.images: np_images, \n",
    "                                                              self.labels: np_labels, \n",
    "                                                              self.objects_num: np_objects_num})\n",
    "                summary_writer.add_summary(summary_str, step)\n",
    "            if step % self.save_frequency == 0:\n",
    "                saver.save(sess, self.train_dir + '/model.ckpt', global_step=step)\n",
    "        sess.close()\n",
    "\n",
    "    def prepare_inference(self, model_version, config):\n",
    "        saver = tf.train.Saver(self.net.trainable_collection)\n",
    "        init =  tf.global_variables_initializer()\n",
    "        self.sess = tf.Session(config = config)\n",
    "        self.sess.run(init)\n",
    "        v_list = tf.trainable_variables() \n",
    "        g_list = tf.global_variables()\n",
    "        #bn_moving_vars = [g for g in g_list if ('moving_mean' or 'moving_variance' or 'gamma' or 'beta') in g.name]\n",
    "        #bn_moving_vars += [g for g in g_list if 'moving_variance' in g.name]\n",
    "        #bn_moving_vars = [g for g in g_list if 'moving_mean' in g.name]\n",
    "        #bn_moving_vars += [g for g in g_list if 'moving_variance' in g.name]\n",
    "        #v_list += bn_moving_vars\n",
    "        #saver = tf.train.Saver(v_list)\n",
    "        saver.restore(self.sess, self.train_dir+'/model.ckpt-'+model_version)\n",
    "\n",
    "    def make_one_prediction(self, images):\n",
    "        prediction = self.sess.run(self.predicts, feed_dict= {self.images: images})\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yolov2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "#if you have multiple GPU on the machine, choose only one to use on this notebook\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "#let the gpu allocates memory space dynamically\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.allow_growth = True\n",
    "import matplotlib.pyplot as plt\n",
    "#from dataset import *\n",
    "\n",
    "class YoloTinyNet(object):\n",
    "\n",
    "    def __init__(self, common_params, net_params, is_train=True):\n",
    "        \"\"\"\n",
    "        common params: a params dict\n",
    "        net_params   : a params dict\n",
    "        \"\"\"\n",
    "        #pretrained variable collection\n",
    "        self.pretrained_collection = []\n",
    "        #trainable variable collection\n",
    "        self.trainable_collection = [] \n",
    "        #process params\n",
    "        self.image_size = int(common_params['image_size'])\n",
    "        self.num_classes = int(common_params['num_classes'])\n",
    "        self.cell_size = int(net_params['cell_size'])\n",
    "        self.boxes_per_cell = int(net_params['boxes_per_cell'])\n",
    "        self.batch_size = int(common_params['batch_size'])\n",
    "        self.weight_decay = float(net_params['weight_decay'])\n",
    "        #if not test:\n",
    "        self.is_train = is_train\n",
    "        self.object_scale = float(net_params['object_scale'])\n",
    "        self.noobject_scale = float(net_params['noobject_scale'])\n",
    "        self.class_scale = float(net_params['class_scale'])\n",
    "        self.coord_scale = float(net_params['coord_scale'])\n",
    "         \n",
    "    def _variable_on_cpu(self, name, shape, initializer, pretrain=False, train=True):\n",
    "        \"\"\"Helper to create a Variable stored on CPU memory.\n",
    "        Args:\n",
    "          name: name of the Variable\n",
    "          shape: list of ints\n",
    "          initializer: initializer of Variable\n",
    "        Returns:\n",
    "          Variable Tensor\n",
    "        \"\"\"\n",
    "        with tf.device('/device:GPU:0'):\n",
    "            var = tf.get_variable(name, shape, initializer=initializer, dtype=tf.float32)\n",
    "            if pretrain:\n",
    "                self.pretrained_collection.append(var)\n",
    "            if train:\n",
    "                self.trainable_collection.append(var)\n",
    "        return var \n",
    "    \n",
    "    def _variable_with_weight_decay(self, name, shape, stddev, wd, pretrain=False, train=True):\n",
    "        \"\"\"Helper to create an initialized Variable with weight decay.\n",
    "        Note that the Variable is initialized with truncated normal distribution\n",
    "        A weight decay is added only if one is specified.\n",
    "        Args:\n",
    "          name: name of the variable \n",
    "          shape: list of ints\n",
    "          stddev: standard devision of a truncated Gaussian\n",
    "          wd: add L2Loss weight decay multiplied by this float. If None, weight \n",
    "          decay is not added for this Variable.\n",
    "       Returns:\n",
    "          Variable Tensor \n",
    "        \"\"\"\n",
    "        var = self._variable_on_cpu(name, shape,\n",
    "            tf.truncated_normal_initializer(stddev=stddev, dtype=tf.float32), pretrain, train)\n",
    "        if wd is not None:\n",
    "            weight_decay = tf.multiply(tf.nn.l2_loss(var), wd, name='weight_loss')\n",
    "            tf.add_to_collection('losses', weight_decay)\n",
    "        return var\n",
    " \n",
    "    def conv_block(self, inp, scope, kernel_width, kernel_height, inp_channel, out_channel, strides = [1, 1, 1, 1], padding='SAME', leaky=True, pretrain=False, train=True):\n",
    "        with tf.variable_scope(scope) as scope:\n",
    "            kernel = self._variable_with_weight_decay('weights', [kernel_width, kernel_width, inp_channel, out_channel], 0.01, self.weight_decay, pretrain, train)\n",
    "            #biases = self._variable_on_cpu('bias', [out_channel], tf.constant_initializer(0.0), pretrain, train)\n",
    "            local = tf.nn.conv2d(inp, kernel, strides=strides, padding=padding)\n",
    "            #local = tf.layers.batch_normalization(conv, training=self.is_train, momentum=0.9, name=scope.name)\n",
    "            #print(local)\n",
    "            #if pretrain:\n",
    "            #    self.pretrained_collection.append(local.variables)\n",
    "                #self.pretrained_collection.append(local.moving_mean)\n",
    "            #if train:\n",
    "            #    self.trainable_collection.append(local.variables)\n",
    "                #self.trainable_collection.append(local.moving_variance)\n",
    "            #local = tf.nn.bias_add(conv, biases)\n",
    "            #return self.leaky_relu(pre_activation, name=scope.name)\n",
    "            if leaky:\n",
    "                local = self.leaky_relu(local, name=scope.name)\n",
    "            else:\n",
    "                local = tf.identity(local, name=scope.name)\n",
    "        return local\n",
    "\n",
    "    def fully(self, scope, input, in_dimension, out_dimension, leaky=True, pretrain=False, train=True):\n",
    "        \"\"\"Fully connection layer\n",
    "        Args:\n",
    "          scope: variable_scope name\n",
    "          input: [batch_size, ???]\n",
    "          out_dimension: int32\n",
    "        Return:\n",
    "          output: 2-D tensor [batch_size, out_dimension]\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(scope) as scope:\n",
    "            reshape = tf.reshape(input, [tf.shape(input)[0], -1])\n",
    "            weights = self._variable_with_weight_decay('weights', shape=[in_dimension, out_dimension],\n",
    "                                  stddev=0.01, wd=self.weight_decay, pretrain=pretrain, train=train)\n",
    "            biases = self._variable_on_cpu('biases', [out_dimension], tf.constant_initializer(0.0), pretrain, train)\n",
    "            local = tf.matmul(reshape, weights) + biases\n",
    "            if leaky:\n",
    "                local = self.leaky_relu(local, name=scope.name)\n",
    "            else:\n",
    "                local = tf.identity(local, name=scope.name)\n",
    "        return local\n",
    "\n",
    "    def leaky_relu(self, x, name, alpha=0.1, dtype=tf.float32):\n",
    "        \"\"\"leaky relu \n",
    "        if x > 0:\n",
    "          return x\n",
    "        else:\n",
    "          return alpha * x\n",
    "        Args:\n",
    "          x : Tensor\n",
    "          alpha: float, the slope of the leaky function\n",
    "        Return:\n",
    "          y : Tensor\n",
    "        \"\"\"\n",
    "        x = tf.cast(x, dtype=dtype)\n",
    "        return tf.nn.leaky_relu(x, alpha=alpha, name=name)\n",
    "    \n",
    "    def inference(self, images):\n",
    "        \"\"\"Build the yolo model\n",
    "        Input the images, output prediction boxes(center_x, center_y, w, h, scale) and the corresponding classes\n",
    "        \n",
    "        Args:\n",
    "          images:  4-D tensor [batch_size, image_height, image_width, channels]\n",
    "        Returns:\n",
    "          predicts: 4-D tensor [batch_size, cell_size, cell_size, num_classes + 5 * boxes_per_cell]\n",
    "        \"\"\"\n",
    "        #images = tf.reshape(images, [-1, self.image_size*self.image_size*3])\n",
    "        #convolutional layers\n",
    "        h_conv1 = self.conv_block(images, \"conv1\", 7, 7, 3, 64, [1, 2, 2, 1])\n",
    "        pool_1 = tf.nn.max_pool(h_conv1, [1, 2, 2, 1], [1, 2, 2, 1], 'SAME')\n",
    "        h_conv2 = self.conv_block(pool_1, \"conv2\", 3, 3, 64, 192)\n",
    "        pool_2 = tf.nn.max_pool(h_conv2, [1, 2, 2, 1], [1, 2, 2, 1], 'SAME')\n",
    "        res3_1 = self.conv_block(pool_2, 'res3_1', 1, 1, 192, 256)\n",
    "        h_conv3_1 = self.conv_block(pool_2, \"conv3_1\", 1, 1, 192, 128)\n",
    "        h_conv3_2 = self.conv_block(h_conv3_1, \"conv3_2\", 3, 3, 128, 256)\n",
    "        h_conv3_2 = tf.add(h_conv3_2, res3_1)\n",
    "        #h_conv3_2 = self.leaky_relu(h_conv3_2, 'conv32')\n",
    "        res3_2 = self.conv_block(h_conv3_2, 'res3_2', 1, 1, 256, 512)\n",
    "        h_conv3_3 = self.conv_block(h_conv3_2, \"conv3_3\", 1, 1, 256, 256)\n",
    "        h_conv3_4 = self.conv_block(h_conv3_3, \"conv3_4\", 3, 3, 256, 512)\n",
    "        h_conv3_4 = tf.add(h_conv3_4, res3_2)\n",
    "        #h_conv3_4 = self.leaky_relu(h_conv3_4, 'conv34')\n",
    "        pool_3 = tf.nn.max_pool(h_conv3_4, [1, 2, 2, 1], [1, 2, 2, 1], 'SAME')\n",
    "        h_conv4_1 = self.conv_block(pool_3, \"conv4_1\", 1, 1, 512, 256)\n",
    "        h_conv4_2 = self.conv_block(h_conv4_1, \"conv4_2\", 3, 3, 256, 512)\n",
    "        h_conv4_2 = tf.add(h_conv4_2, pool_3)\n",
    "        #h_conv4_2 = self.leaky_relu(h_conv4_2, 'conv42')\n",
    "        h_conv4_3 = self.conv_block(h_conv4_2, \"conv4_3\", 1, 1, 512, 256)\n",
    "        h_conv4_4 = self.conv_block(h_conv4_3, \"conv4_4\", 3, 3, 256, 512)\n",
    "        h_conv4_4 = tf.add(h_conv4_4, h_conv4_2)\n",
    "        #h_conv4_4 = self.leaky_relu(h_conv4_4, 'conv44')\n",
    "        h_conv4_5 = self.conv_block(h_conv4_4, \"conv4_5\", 1, 1, 512, 256)\n",
    "        h_conv4_6 = self.conv_block(h_conv4_5, \"conv4_6\", 3, 3, 256, 512)\n",
    "        h_conv4_6 = tf.add(h_conv4_6, h_conv4_4)\n",
    "        #h_conv4_6 = self.leaky_relu(h_conv4_6, 'conv46')\n",
    "        h_conv4_7 = self.conv_block(h_conv4_6, \"conv4_7\", 1, 1, 512, 256)\n",
    "        h_conv4_8 = self.conv_block(h_conv4_7, \"conv4_8\", 3, 3, 256, 512)\n",
    "        h_conv4_8 = tf.add(h_conv4_8, h_conv4_6)\n",
    "        #h_conv4_8 = self.leaky_relu(h_conv4_8, 'conv48')\n",
    "        res4_1 = self.conv_block(h_conv4_8, 'res4_1', 1, 1, 512, 1024)\n",
    "        h_conv4_9 = self.conv_block(h_conv4_8, \"conv4_9\", 1, 1, 512, 512)\n",
    "        h_conv4_10 = self.conv_block(h_conv4_9, \"conv4_10\", 3, 3, 512, 1024)\n",
    "        h_conv4_10 = tf.add(h_conv4_10, res4_1)\n",
    "        #h_conv4_10 = self.leaky_relu(h_conv4_10, 'conv410')\n",
    "        pool_4 = tf.nn.max_pool(h_conv4_10, [1, 2, 2, 1], [1, 2, 2, 1], 'SAME')\n",
    "        h_conv5_1 = self.conv_block(pool_4, \"conv5_1\", 1, 1, 1024, 512)\n",
    "        h_conv5_2 = self.conv_block(h_conv5_1, \"conv5_2\", 3, 3, 512, 1024)\n",
    "        h_conv5_2 = tf.add(h_conv5_2, pool_4)\n",
    "        #h_conv5_2 = self.leaky_relu(h_conv5_2, 'conv52')\n",
    "        h_conv5_3 = self.conv_block(h_conv5_2, \"conv5_3\", 1, 1, 1024, 512)\n",
    "        h_conv5_4 = self.conv_block(h_conv5_3, \"conv5_4\", 3, 3, 512, 1024)\n",
    "        h_conv5_4 = tf.add(h_conv5_2, h_conv5_4)\n",
    "        #h_conv5_4 = self.leaky_relu(h_conv5_4, 'conv54')\n",
    "        h_conv5_5 = self.conv_block(h_conv5_4, \"conv5_5\", 3, 3, 1024, 1024)\n",
    "        h_conv5_6 = self.conv_block(h_conv5_5, \"conv5_6\", 3, 3, 1024, 1024, strides=[1, 2, 2, 1])\n",
    "        res5 = tf.nn.max_pool(h_conv5_4, [1, 2, 2, 1], [1, 2, 2, 1], 'SAME')\n",
    "        h_conv5_6 = tf.add(h_conv5_6, res5)\n",
    "        #h_conv5_6 = self.leaky_relu(h_conv5_6, 'conv56')\n",
    "        h_conv6_1 = self.conv_block(h_conv5_6, \"conv6_1\", 3, 3, 1024, 1024)\n",
    "        h_conv6_2 = self.conv_block(h_conv6_1, \"conv6_2\", 3, 3, 1024, 1024)\n",
    "        h_conv6_2 = tf.add(h_conv6_2, h_conv5_6)\n",
    "        #h_conv6_2 = self.leaky_relu(h_conv6_2, 'conv62')\n",
    "        #fully0 = self.fully('local0', images, self.image_size*self.image_size*3, 256)\n",
    "        #fully1 = self.fully('local1', fully0, 256, 512)\n",
    "        #flatten = tf.contrib.layers.flatten(h_conv6_2, scope='flatten')\n",
    "        #h_conv6_2 = tf.transpose(h_conv6_2, [0, 3, 1, 2])\n",
    "        #fully0 = self.fully('fully0', h_conv6_2, 7*7*1024, 512)\n",
    "        fully1 = self.fully('fully1', h_conv6_2, 7*7*1024, 4096)\n",
    "        #fully1 = tf.nn.dropout(fully1, 0.5)\n",
    "        fully2 = self.fully('fully2', fully1, 4096, self.cell_size * self.cell_size * \n",
    "                            (self.num_classes + self.boxes_per_cell * 5), leaky=False,\n",
    "                            pretrain=False, train=True)\n",
    "        n1 = self.cell_size * self.cell_size * self.num_classes\n",
    "        n2 = n1 + self.cell_size * self.cell_size * self.boxes_per_cell\n",
    "        class_probs = tf.reshape(fully2[:, 0:n1], (-1, self.cell_size, self.cell_size, self.num_classes))\n",
    "        scales = tf.reshape(fully2[:, n1:n2], (-1, self.cell_size, self.cell_size, self.boxes_per_cell))\n",
    "        boxes = tf.reshape(fully2[:, n2:], (-1, self.cell_size, self.cell_size, self.boxes_per_cell * 4))\n",
    "        predicts = tf.concat([class_probs, scales, boxes], 3)\n",
    "        return predicts\n",
    "\n",
    "    def iou(self, boxes1, boxes2):\n",
    "        \"\"\"calculate ious\n",
    "        Args:\n",
    "          boxes1: 4-D tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 4]  ====> (x_center, y_center, w, h)\n",
    "          boxes2: 1-D tensor [4] ===> (x_center, y_center, w, h)\n",
    "          \n",
    "        Return:\n",
    "          iou: 3-D tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "        \"\"\"\n",
    "        #boxes1 : [4(xmin, ymin, xmax, ymax), cell_size, cell_size, boxes_per_cell]\n",
    "        boxes1 = tf.stack([boxes1[:, :, :, 0] - boxes1[:, :, :, 2] / 2, boxes1[:, :, :, 1] - boxes1[:, :, :, 3] / 2,\n",
    "                          boxes1[:, :, :, 0] + boxes1[:, :, :, 2] / 2, boxes1[:, :, :, 1] + boxes1[:, :, :, 3] / 2])\n",
    "        #boxes1 : [cell_size, cell_size, boxes_per_cell, 4(xmin, ymin, xmax, ymax)]\n",
    "        boxes1 = tf.transpose(boxes1, [1, 2, 3, 0])\n",
    "        boxes2 =  tf.stack([boxes2[0] - boxes2[2] / 2, boxes2[1] - boxes2[3] / 2,\n",
    "                            boxes2[0] + boxes2[2] / 2, boxes2[1] + boxes2[3] / 2])\n",
    "        #calculate the left up point of boxes' overlap area\n",
    "        lu = tf.maximum(boxes1[:, :, :, 0:2], boxes2[0:2])\n",
    "        #calculate the right down point of boxes overlap area\n",
    "        rd = tf.minimum(boxes1[:, :, :, 2:], boxes2[2:])\n",
    "        #intersection\n",
    "        intersection = rd - lu \n",
    "        #the size of the intersection area\n",
    "        inter_square = intersection[:, :, :, 0] * intersection[:, :, :, 1]\n",
    "        mask = tf.cast(intersection[:, :, :, 0] > 0, tf.float32) * tf.cast(intersection[:, :, :, 1] > 0, tf.float32)\n",
    "        #if intersection is negative, then the boxes don't overlap\n",
    "        inter_square = mask * inter_square\n",
    "        #calculate the boxs1 square and boxs2 square\n",
    "        square1 = (boxes1[:, :, :, 2] - boxes1[:, :, :, 0]) * (boxes1[:, :, :, 3] - boxes1[:, :, :, 1])\n",
    "        square2 = (boxes2[2] - boxes2[0]) * (boxes2[3] - boxes2[1])\n",
    "        return inter_square/(square1 + square2 - inter_square + 1e-6)\n",
    "\n",
    "    def losses_calculation(self, num, object_num, loss, predict, labels, nilboy):\n",
    "        \"\"\"\n",
    "        calculate loss\n",
    "        Args:\n",
    "          predict: 3-D tensor [cell_size, cell_size, 5 * boxes_per_cell]\n",
    "          labels : [max_objects, 5]  (x_center, y_center, w, h, class)\n",
    "        \"\"\"\n",
    "        label = labels[num:num+1, :]\n",
    "        label = tf.reshape(label, [-1])\n",
    "        #calculate objects  tensor [CELL_SIZE, CELL_SIZE]\n",
    "        min_x = (label[0] - label[2] / 2) / (self.image_size / self.cell_size)\n",
    "        max_x = (label[0] + label[2] / 2) / (self.image_size / self.cell_size)\n",
    "        min_y = (label[1] - label[3] / 2) / (self.image_size / self.cell_size)\n",
    "        max_y = (label[1] + label[3] / 2) / (self.image_size / self.cell_size)\n",
    "        min_x = tf.floor(min_x)\n",
    "        min_y = tf.floor(min_y)\n",
    "        max_x = tf.minimum(tf.ceil(max_x), self.cell_size)\n",
    "        max_y = tf.minimum(tf.ceil(max_y), self.cell_size)\n",
    "        temp = tf.cast(tf.stack([max_y - min_y, max_x - min_x]), dtype=tf.int32)\n",
    "        objects = tf.ones(temp, tf.float32)\n",
    "        temp = tf.cast(tf.stack([min_y, self.cell_size - max_y, min_x, self.cell_size - max_x]), tf.int32)\n",
    "        temp = tf.reshape(temp, (2, 2))\n",
    "        objects = tf.pad(objects, temp, \"CONSTANT\")\n",
    "        #calculate objects  tensor [CELL_SIZE, CELL_SIZE]\n",
    "        #calculate responsible tensor [CELL_SIZE, CELL_SIZE]\n",
    "        center_x = label[0] / (self.image_size / self.cell_size)\n",
    "        center_x = tf.floor(center_x)\n",
    "        center_y = label[1] / (self.image_size / self.cell_size)\n",
    "        center_y = tf.floor(center_y)\n",
    "        response = tf.ones([1, 1], tf.float32)\n",
    "        temp = tf.cast(tf.stack([center_y, self.cell_size - center_y - 1, \n",
    "                                 center_x, self.cell_size -center_x - 1]), tf.int32)\n",
    "        self.tmp = tf.stack([center_y, self.cell_size - center_y - 1, \n",
    "                             center_x, self.cell_size -center_x - 1])\n",
    "        temp = tf.reshape(temp, (2, 2))\n",
    "        response = tf.pad(response, temp, \"CONSTANT\")\n",
    "        #objects = response\n",
    "        #calculate iou_predict_truth [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "        predict_boxes = predict[:, :, self.num_classes + self.boxes_per_cell:]\n",
    "        predict_boxes = tf.reshape(predict_boxes, [self.cell_size, \n",
    "                                                   self.cell_size, \n",
    "                                                   self.boxes_per_cell, 4])\n",
    "        predict_boxes = predict_boxes * [self.image_size / self.cell_size, \n",
    "                                         self.image_size / self.cell_size, \n",
    "                                         self.image_size, self.image_size]\n",
    "        base_boxes = np.zeros([self.cell_size, self.cell_size, 4])\n",
    "        #for each cell\n",
    "        for y in range(self.cell_size):\n",
    "            for x in range(self.cell_size):\n",
    "                base_boxes[y, x, :] = [self.image_size / self.cell_size * x, self.image_size / self.cell_size * y, 0, 0]\n",
    "        base_boxes = np.tile(np.resize(base_boxes, [self.cell_size, self.cell_size, 1, 4]), [1, 1, self.boxes_per_cell, 1])\n",
    "        #if there's no predict_box in that cell, then the base_boxes will be calcuated with label and got iou equals 0\n",
    "        predict_boxes = base_boxes + predict_boxes\n",
    "        iou_predict_truth = self.iou(predict_boxes, label[0:4])\n",
    "        #calculate C [cell_size, cell_size, boxes_per_cell]\n",
    "        C = iou_predict_truth * tf.reshape(response, [self.cell_size, self.cell_size, 1])\n",
    "        #calculate I tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "        I = iou_predict_truth * tf.reshape(response, (self.cell_size, self.cell_size, 1))\n",
    "        max_I = tf.reduce_max(I, 2, keep_dims=True)\n",
    "        I = tf.cast((I >= max_I), tf.float32) * tf.reshape(response, (self.cell_size, self.cell_size, 1))\n",
    "        #calculate no_I tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "        no_I = tf.ones_like(I, dtype=tf.float32) - I \n",
    "        p_C = predict[:, :, self.num_classes:self.num_classes + self.boxes_per_cell]\n",
    "        #calculate truth x, y, sqrt_w, sqrt_h 0-D\n",
    "        x = label[0]\n",
    "        y = label[1]\n",
    "        sqrt_w = tf.sqrt(tf.abs(label[2]))\n",
    "        sqrt_h = tf.sqrt(tf.abs(label[3]))\n",
    "        #calculate predict p_x, p_y, p_sqrt_w, p_sqrt_h 3-D [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "        p_x = predict_boxes[:, :, :, 0]\n",
    "        p_y = predict_boxes[:, :, :, 1]\n",
    "        #p_sqrt_w = tf.sqrt(tf.abs(predict_boxes[:, :, :, 2])) * ((tf.cast(predict_boxes[:, :, :, 2] > 0, tf.float32) * 2) - 1)\n",
    "        #p_sqrt_h = tf.sqrt(tf.abs(predict_boxes[:, :, :, 3])) * ((tf.cast(predict_boxes[:, :, :, 3] > 0, tf.float32) * 2) - 1)\n",
    "        #p_sqrt_w = tf.sqrt(tf.maximum(0.0, predict_boxes[:, :, :, 2]))\n",
    "        #p_sqrt_h = tf.sqrt(tf.maximum(0.0, predict_boxes[:, :, :, 3]))\n",
    "        #p_sqrt_w = predict_boxes[:, :, :, 2]\n",
    "        #p_sqrt_h = predict_boxes[:, :, :, 3]\n",
    "        p_sqrt_w = tf.sqrt(tf.minimum(self.image_size * 1.0, tf.maximum(0.0, predict_boxes[:, :, :, 2])))\n",
    "        p_sqrt_h = tf.sqrt(tf.minimum(self.image_size * 1.0, tf.maximum(0.0, predict_boxes[:, :, :, 3])))\n",
    "        #calculate truth p 1-D tensor [NUM_CLASSES]\n",
    "        P = tf.one_hot(tf.cast(label[4], tf.int32), self.num_classes, dtype=tf.float32)\n",
    "        #calculate predict p_P 3-D tensor [CELL_SIZE, CELL_SIZE, NUM_CLASSES]\n",
    "        p_P = predict[:, :, 0:self.num_classes]\n",
    "        #class_loss\n",
    "        class_loss = tf.nn.l2_loss(tf.reshape(objects, (self.cell_size, self.cell_size, 1)) * (p_P - P)) * self.class_scale\n",
    "        #print(class_loss)\n",
    "        #P_temp = tf.reshape(objects, (self.cell_size, self.cell_size, 1)) * tf.reshape(P, (1, 1, self.num_classes))\n",
    "        #class_loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(labels=P_temp, logits = tf.reshape(objects, (self.cell_size, self.cell_size, 1)) * p_P))\n",
    "        #class_loss *= self.class_scale\n",
    "        #print(class_loss)\n",
    "        \n",
    "        #class_loss = tf.nn.l2_loss(tf.reshape(response, (self.cell_size, self.cell_size, 1)) * (p_P - P)) * self.class_scale\n",
    "        #object_loss\n",
    "        object_loss = tf.nn.l2_loss(I * (p_C - C)) * self.object_scale\n",
    "        #object_loss = tf.nn.l2_loss(I * (p_C - (C + 1.0)/2.0)) * self.object_scale\n",
    "        #noobject_loss\n",
    "        #noobject_loss = tf.nn.l2_loss(no_I * (p_C - C)) * self.noobject_scale\n",
    "        noobject_loss = tf.nn.l2_loss(no_I * (p_C)) * self.noobject_scale\n",
    "        #coord_loss\n",
    "        coord_loss = (tf.nn.l2_loss(I * (p_x - x)/(self.image_size/self.cell_size)) +\n",
    "                     tf.nn.l2_loss(I * (p_y - y)/(self.image_size/self.cell_size)) +\n",
    "                     tf.nn.l2_loss(I * (p_sqrt_w - sqrt_w))/ self.image_size +\n",
    "                     tf.nn.l2_loss(I * (p_sqrt_h - sqrt_h))/self.image_size) * self.coord_scale\n",
    "        nilboy = I\n",
    "        return (num + 1, object_num, [loss[0] + class_loss, \n",
    "                                      loss[1] + object_loss, \n",
    "                                      loss[2] + noobject_loss,\n",
    "                                      loss[3] + coord_loss], predict, labels, nilboy)\n",
    "\n",
    "    def loss(self, predicts, labels, objects_num):\n",
    "        \"\"\"Add Loss to all the trainable variables\n",
    "          Args:\n",
    "          predicts: 4-D tensor [batch_size, cell_size, cell_size, 5 * boxes_per_cell]\n",
    "          ===> (num_classes, boxes_per_cell, 4 * boxes_per_cell)\n",
    "          labels  : 3-D tensor of [batch_size, max_objects, 5]\n",
    "          objects_num: 1-D tensor [batch_size]\n",
    "        \"\"\"\n",
    "        def condition(num, object_num, loss, predict, label, nilboy):\n",
    "            \"\"\"\n",
    "            if num < object_num\n",
    "            \"\"\"\n",
    "            return num < object_num\n",
    "        class_loss = tf.constant(0, tf.float32)\n",
    "        object_loss = tf.constant(0, tf.float32)\n",
    "        noobject_loss = tf.constant(0, tf.float32)\n",
    "        coord_loss = tf.constant(0, tf.float32)\n",
    "        loss = [0, 0, 0, 0]\n",
    "        for i in range(self.batch_size):\n",
    "            predict = predicts[i, :, :, :]\n",
    "            label = labels[i, :, :]\n",
    "            object_num = objects_num[i]\n",
    "            nilboy = tf.ones([7,7,2])\n",
    "            tuple_results = tf.while_loop(condition, self.losses_calculation, \n",
    "                                          [tf.constant(0), object_num, \n",
    "                                           [class_loss, object_loss, noobject_loss, coord_loss], \n",
    "                                           predict, label, nilboy])\n",
    "            for j in range(4):\n",
    "                loss[j] = loss[j] + tuple_results[2][j]\n",
    "            nilboy = tuple_results[5]\n",
    "        tf.add_to_collection('losses', (loss[0] + loss[1] + loss[2] + loss[3])/self.batch_size)\n",
    "        tf.summary.scalar('class_loss', loss[0]/self.batch_size)\n",
    "        tf.summary.scalar('object_loss', loss[1]/self.batch_size)\n",
    "        tf.summary.scalar('noobject_loss', loss[2]/self.batch_size)\n",
    "        tf.summary.scalar('coord_loss', loss[3]/self.batch_size)\n",
    "        tf.summary.scalar('weight_loss', tf.add_n(tf.get_collection('losses')) \n",
    "                          - (loss[0] + loss[1] + loss[2] + loss[3])/self.batch_size )\n",
    "        return tf.add_n(tf.get_collection('losses'), name='total_loss'), nilboy, tf.convert_to_tensor(loss)/self.batch_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os ,sys\n",
    "print(0)\n",
    "import tensorflow as tf\n",
    "print(1)\n",
    "from dataset import DatasetRunner\n",
    "print(2)\n",
    "from model_def import YoloRunner\n",
    "print(3)\n",
    "from yolov2 import YoloTinyNet\n",
    "\n",
    "##### SET HYPERPARAMETERS #####\n",
    "common_params = {\n",
    "    'image_size': 448,\n",
    "    'batch_size': 32,\n",
    "    'num_classes': 20,\n",
    "    'max_objects_per_image': 20\n",
    "}\n",
    "dataset_params = {\n",
    "    'path': 'data/pascal_voc_training_data.txt',\n",
    "    'image_dir': './data/VOCdevkit_train/VOC2007/JPEGImages/',\n",
    "    'thread_num': 6\n",
    "}\n",
    "net_params = {\n",
    "    'weight_decay': 0.0005,\n",
    "    'cell_size': 7,\n",
    "    'boxes_per_cell': 2,\n",
    "    'object_scale': 1,\n",
    "    'noobject_scale': 0.5,\n",
    "    'class_scale': 2,\n",
    "    'coord_scale': 5, \n",
    "\n",
    "}\n",
    "solver_params = {\n",
    "    'learning_rate': 0.0001,\n",
    "    'decay_step': 20000,\n",
    "    'decay_rate': 0.1,\n",
    "    'moment': 0.9,\n",
    "    'max_iterators': 20001,\n",
    "    'print_frequency': 100,\n",
    "    'save_frequency' : 1000,\n",
    "    'train_dir': 'models/yolo-like',\n",
    "    'pretrain_path': 'models/yolo-like/model.ckpt-25000'\n",
    "}\n",
    "if __name__ == '__main__':\n",
    "    #if you have multiple GPU on the machine, choose only one to use on this notebook\n",
    "    print(0)\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "    #let the gpu allocates memory space dynamically\n",
    "    print('Config')\n",
    "    #config = tf.ConfigProto()\n",
    "    #config.gpu_options.allow_growth = True\n",
    "    #from yolov2 import *\n",
    "    ##### TRAINING #####\n",
    "    print('Start!')\n",
    "    tf.reset_default_graph()\n",
    "    sys.path.append('./')\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    dataset = DatasetRunner(common_params, dataset_params, config)\n",
    "    print('Dataset Ready')\n",
    "    net = YoloTinyNet(common_params, net_params)\n",
    "    print('Define Network')\n",
    "    model_runner = YoloRunner(dataset, net, common_params, solver_params)\n",
    "    print('Model Runner')\n",
    "    print('Learning Rate: 0.0001')\n",
    "    model_runner.run(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from model_def import YoloRunner\n",
    "from yolov2 import YoloTinyNet\n",
    "\n",
    "##### SET HYPERPARAMETERS #####\n",
    "common_params = {\n",
    "    'image_size': 448,\n",
    "    'batch_size': 32,\n",
    "    'num_classes': 20,\n",
    "    'max_objects_per_image': 20\n",
    "}\n",
    "dataset_params = {\n",
    "    'path': 'data/pascal_voc_training_data.txt',\n",
    "    'image_dir': './data/VOCdevkit_train/VOC2007/JPEGImages/',\n",
    "    'thread_num': 6\n",
    "}\n",
    "net_params = {\n",
    "    'weight_decay': 0.0005,\n",
    "    'cell_size': 7,\n",
    "    'boxes_per_cell': 2,\n",
    "    'object_scale': 1,\n",
    "    'noobject_scale': 0.5,\n",
    "    'class_scale': 1,\n",
    "    'coord_scale': 5, \n",
    "\n",
    "}\n",
    "solver_params = {\n",
    "    'learning_rate': 0.00001,\n",
    "    'moment': 0.9,\n",
    "    'max_iterators': 20001,\n",
    "    'print_frequency': 100,\n",
    "    'save_frequency' : 1000,\n",
    "    'train_dir': 'models',\n",
    "    'pretrain_path': 'models/yolov2-like/model.ckpt-13000'\n",
    "}\n",
    "\n",
    "def process_predicts(predicts):\n",
    "    \"\"\"\n",
    "    Process YOLO outputs into bou\n",
    "    \"\"\"\n",
    "    p_classes = predicts[0, :, :, 0:20]\n",
    "    C = predicts[0, :, :, 20:22]\n",
    "    coordinate = predicts[0, :, :, 22:]\n",
    "    p_classes = np.reshape(p_classes, (net_params['cell_size'], net_params['cell_size'], 1, 20))\n",
    "    C = np.reshape(C, (net_params['cell_size'], net_params['cell_size'], net_params['boxes_per_cell'], 1))\n",
    "    P = C * p_classes\n",
    "    #P's shape [7, 7, 2, 20]\n",
    "    #print P[5,1, 0, :]\n",
    "    #choose the most confidence one\n",
    "    max_conf = np.max(P)\n",
    "    index = np.argmax(P)\n",
    "    index = np.unravel_index(index, P.shape)\n",
    "    class_num = index[3]\n",
    "    coordinate = np.reshape(coordinate, \n",
    "                            (net_params['cell_size'], \n",
    "                             net_params['cell_size'], \n",
    "                             net_params['boxes_per_cell'], \n",
    "                             4))\n",
    "    max_coordinate = coordinate[index[0], index[1], index[2], :]\n",
    "    xcenter = max_coordinate[0]\n",
    "    ycenter = max_coordinate[1]\n",
    "    w = max_coordinate[2]\n",
    "    h = max_coordinate[3]\n",
    "    xcenter = (index[1] + xcenter) * (common_params['image_size']/float(net_params['cell_size']))\n",
    "    ycenter = (index[0] + ycenter) * (common_params['image_size']/float(net_params['cell_size']))\n",
    "    w = w * common_params['image_size']\n",
    "    h = h * common_params['image_size']\n",
    "    xmin = xcenter - w/2.0\n",
    "    ymin = ycenter - h/2.0\n",
    "    xmax = xmin + w\n",
    "    ymax = ymin + h\n",
    "    return xmin, ymin, xmax, ymax, class_num, max_conf\n",
    "\n",
    "#if you have multiple GPU on the machine, choose only one to use on this notebook\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "#let the gpu allocates memory space dynamically\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "tf.reset_default_graph()\n",
    "common_params['batch_size'] = 1\n",
    "net = YoloTinyNet(common_params, net_params)\n",
    "solver = YoloRunner(None, net, common_params, solver_params)\n",
    "\n",
    "#### BUILD TEST DATASET ITERLATOR #####\n",
    "test_img_files = open('data/pascal_voc_testing_data.txt')\n",
    "test_img_dir = './data/VOCdevkit_test/VOC2007/JPEGImages/'\n",
    "test_images = []\n",
    "img_size = common_params['image_size']\n",
    "for line in test_img_files:\n",
    "    line = line.strip()\n",
    "    ss = line.split(' ')\n",
    "    test_images.append(ss[0])\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_images)\n",
    "def load_img_data(image_name):\n",
    "    image_file = tf.read_file(test_img_dir+image_name)\n",
    "    image = tf.image.decode_jpeg(image_file, channels=3)\n",
    "    h = tf.shape(image)[0]\n",
    "    w = tf.shape(image)[1]\n",
    "    image = tf.image.resize_images(image, size=[img_size,img_size])\n",
    "    return image_name, image, h, w\n",
    "test_dataset = test_dataset.map(load_img_data)\n",
    "test_iterator = test_dataset.make_one_shot_iterator()\n",
    "next_test_element = test_iterator.get_next()\n",
    "tdata_sess = tf.Session(config = config)\n",
    "\n",
    "##### PREDICT & OUTPUT #####\n",
    "output_file = open('./data/test_predion.txt', 'w')\n",
    "solver.prepare_inference(model_version = '4000', config = config)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        img_name, test_img, img_h, img_w = tdata_sess.run(next_test_element)\n",
    "        test_img = test_img/255 * 2 - 1\n",
    "        test_img = np.expand_dims(test_img, axis=0)\n",
    "        y_pred = solver.make_one_prediction(test_img)\n",
    "        ''' \n",
    "        pred_dict = multi_process_predicts(test_img, y_pred, 0.1)\n",
    "        pred_dict = non_max_suppress(pred_dict)\n",
    "        for class_num, bbox in pred_dict.items():\n",
    "            for bb in bbox:\n",
    "                xmin, ymin, xmax, ymax, conf = bb\n",
    "                xmin, ymin, xmax, ymax = xmin*(img_w/img_size), ymin*(img_h/img_size), xmax*(img_w/img_size), ymax*(img_h/img_size)\n",
    "                output_file.write(img_name.decode('ascii')+\" %d %d %d %d %d %f\\n\" %(xmin, ymin, xmax, ymax, class_num, conf))\n",
    "        '''\n",
    "        xmin, ymin, xmax, ymax, class_num, conf = process_predicts(y_pred)\n",
    "        xmin, ymin, xmax, ymax = xmin*(img_w/img_size), ymin*(img_h/img_size), xmax*(img_w/img_size), ymax*(img_h/img_size)\n",
    "        #img filename, (xmin, ymin, xmax, ymax, class, confidence)*number_of_predictions\n",
    "        output_file.write(img_name.decode('ascii')+\" %d %d %d %d %d %f\\n\" %(xmin, ymin, xmax, ymax, class_num, conf))\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print(\"done predicting all test data\")\n",
    "        break\n",
    "output_file.close()\n",
    "\n",
    "##### EVALUATE #####\n",
    "sys.path.insert(0, './data/evaluate')\n",
    "import evaluate\n",
    "#evaluate.evaluate(\"input prediction file name\", \"desire output csv file name\")\n",
    "evaluate.evaluate('./data/test_predion.txt', './output_file.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "demo.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model_def import YoloRunner\n",
    "from yolov2 import YoloTinyNet\n",
    "import tensorflow as tf\n",
    "\n",
    "def process_predicts(predicts):\n",
    "    \"\"\"\n",
    "    Process YOLO outputs into bou\n",
    "    \"\"\"\n",
    "    p_classes = predicts[0, :, :, 0:20]\n",
    "    C = predicts[0, :, :, 20:22]\n",
    "    coordinate = predicts[0, :, :, 22:]\n",
    "    p_classes = np.reshape(p_classes, (net_params['cell_size'], net_params['cell_size'], 1, 20))\n",
    "    C = np.reshape(C, (net_params['cell_size'], net_params['cell_size'], net_params['boxes_per_cell'], 1))\n",
    "    P = C * p_classes\n",
    "    #P's shape [7, 7, 2, 20]\n",
    "    #print P[5,1, 0, :]\n",
    "    #choose the most confidence one\n",
    "    max_conf = np.max(P)\n",
    "    index = np.argmax(P)\n",
    "    index = np.unravel_index(index, P.shape)\n",
    "    class_num = index[3]\n",
    "    coordinate = np.reshape(coordinate, \n",
    "                            (net_params['cell_size'], \n",
    "                             net_params['cell_size'], \n",
    "                             net_params['boxes_per_cell'], \n",
    "                             4))\n",
    "    max_coordinate = coordinate[index[0], index[1], index[2], :]\n",
    "    xcenter = max_coordinate[0]\n",
    "    ycenter = max_coordinate[1]\n",
    "    w = max_coordinate[2]\n",
    "    h = max_coordinate[3]\n",
    "    xcenter = (index[1] + xcenter) * (common_params['image_size']/float(net_params['cell_size']))\n",
    "    ycenter = (index[0] + ycenter) * (common_params['image_size']/float(net_params['cell_size']))\n",
    "    w = w * common_params['image_size']\n",
    "    h = h * common_params['image_size']\n",
    "    xmin = xcenter - w/2.0\n",
    "    ymin = ycenter - h/2.0\n",
    "    xmax = xmin + w\n",
    "    ymax = ymin + h\n",
    "    return xmin, ymin, xmax, ymax, class_num, max_conf\n",
    "\n",
    "classes_name =  [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \n",
    "                 \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \n",
    "                 \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \n",
    "                 \"sheep\", \"sofa\", \"train\",\"tvmonitor\"]\n",
    "\n",
    "\n",
    "##### SET HYPERPARAMETERS #####\n",
    "common_params = {\n",
    "    'image_size': 448,\n",
    "    'batch_size': 64,\n",
    "    'num_classes': 20,\n",
    "    'max_objects_per_image': 20\n",
    "}\n",
    "dataset_params = {\n",
    "    'path': 'data/pascal_voc_training_data.txt',\n",
    "    'image_dir': './data/VOCdevkit_train/VOC2007/JPEGImages/',\n",
    "    'thread_num': 6\n",
    "}\n",
    "net_params = {\n",
    "    'weight_decay': 0.0005,\n",
    "    'cell_size': 7,\n",
    "    'boxes_per_cell': 2,\n",
    "    'object_scale': 1,\n",
    "    'noobject_scale': 0.5,\n",
    "    'class_scale': 1,\n",
    "    'coord_scale': 5, \n",
    "\n",
    "}\n",
    "solver_params = {\n",
    "    'learning_rate': 0.000001,\n",
    "    'moment': 0.9,\n",
    "    'max_iterators': 20001,\n",
    "    'print_frequency': 100,\n",
    "    'save_frequency' : 1000,\n",
    "    'train_dir': 'models/yolo-like'\n",
    "}\n",
    "#if you have multiple GPU on the machine, choose only one to use on this notebook\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "#let the gpu allocates memory space dynamically\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "tf.reset_default_graph()\n",
    "common_params['batch_size'] = 1\n",
    "net = YoloTinyNet(common_params, net_params)\n",
    "solver = YoloRunner(None, net, common_params, solver_params)\n",
    "solver.prepare_inference(model_version = '25000', config = config)\n",
    "test_dir = os.listdir('./data/VOCdevkit_test/VOC2007/JPEGImages/')\n",
    "#cv2.namedWindow('Test', cv2.WINDOW_NORMAL)\n",
    "ret = True\n",
    "se = None\n",
    "for name in test_dir:\n",
    "    np_img = cv2.imread('./data/VOCdevkit_test/VOC2007/JPEGImages/'+name)\n",
    "    #ret, np_img = cap.read()\n",
    "    resized_img = cv2.resize(np_img, (common_params['image_size'], common_params['image_size']))\n",
    "    np_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n",
    "    resized_img = np_img\n",
    "    np_img = np_img.astype(np.float32)\n",
    "    np_img = np_img / 255.0 * 2 - 1\n",
    "    np_img = np.reshape(np_img, (1, common_params['image_size'], common_params['image_size'], 3))\n",
    "\n",
    "    y_pred = solver.make_one_prediction(np_img)\n",
    "    xmin, ymin, xmax, ymax, class_num, conf = process_predicts(y_pred)\n",
    "    '''\n",
    "    pred_dict = multi_process_predicts(resized_img, y_pred, 0.03)\n",
    "    pred_dict = non_max_suppress(pred_dict)\n",
    "    for name, bbox in pred_dict.items():\n",
    "        for bb in bbox:    \n",
    "            class_name = classes_name[name]\n",
    "            xmin, ymin, xmax, ymax, conf = bb\n",
    "            conf = float('%.2f' %conf)\n",
    "            cv2.rectangle(resized_img, (int(xmin), int(ymin)), (int(xmax), int(ymax)), (0, 255, 255), 3)\n",
    "            cv2.putText(resized_img, class_name+str(conf), (int(xmin), int(ymin)), 2, 1.5, (0, 255, 255), 2)\n",
    "    '''\n",
    "    conf = float('%.2f' %conf)  \n",
    "    class_name = classes_name[class_num]\n",
    "    cv2.rectangle(resized_img, (int(xmin), int(ymin)), (int(xmax), int(ymax)), (0, 255, 255), 3)\n",
    "    cv2.putText(resized_img, class_name+str(conf), (int(xmin), int(ymin)), 2, 1.5, (0, 255, 255), 2)\n",
    "    #cv2.imshow('Test', resized_img)\n",
    "    if se is None:\n",
    "        se = plt.imshow(resized_img)\n",
    "    else:\n",
    "        se.set_data(resized_img)\n",
    "    plt.pause(1.0)\n",
    "    plt.draw()\n",
    " \n",
    "#plt.imshow(resized_img)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Did you pre-train your model? If yes, what dataset did you use(briefly introduce this dataset)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們沒有使用pre-train model。使用的dataset是助教提供的pascal voc 2007 dataset，裡面總共有20種class，training和validation data約有10000筆，總共有24640個已標記的object。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. How did you build your model(What model, any techniques you used, what obstacles you met and how did you deal with them)? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\t我們使用助教上課講解的YOLO來進行實作，一開始先試助教原本的code，發現只有fully connected的架構結果會很差，所以我們照YOLO v1的架構做完整的convolution，後來發現test出來的結果，框的區域跟判斷的種類好像都變動不大，而且loss的部分一直沒辦法收斂，而且class loss的部分特別大，所以感覺的可能是架構太深讓network沒辦法抓到它要學的東西，或是訓練參數的問題，也有可能是train的iterator不夠多，所以:\n",
    "    \n",
    "1.) 我們在model加入幾層residual connection，希望不會因為架構太深讓network忘了前面學到的東西。\n",
    "\n",
    "2.) 調整訓練參數的部分，嘗試過幾種組合之後將learning rate調整成0.0001，另外，為了想降低class loss，所以我們將class_scale調整為2。\n",
    "\n",
    "3.) 不確定loss是因為train不夠久還沒收斂還是已經不會收斂了，所以我們將iterator的部分調整為20001，結果的確有再讓loss降低一點點。\n",
    "\n",
    "4.) 我們嘗試過將判斷class的部分改成multi-class，但發現結果反而更多錯誤，所以還是改回助教原本使用的方法。\n",
    "\n",
    "\t我們使用前面提到的方法讓training時的loss降低了許多，但testing的時候並沒有想像中的好，class loss的部分雖然有降低一些，不過沒有到理想中的低，另外，也發現它在person的class學得比較好，不確定是不是dataset中可能比較多person的圖片，應該要從前處理的部分來著手，有嘗試過圖片的flip，不過有些執行上的錯誤沒時間處理完。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Anything you think it's worth mentioning(your findings, other works). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Dataset不足\n",
    "\n",
    "Pascal voc 2007的資料有20類，總共約10000張圖片和24640筆已標記的object，這對於要訓練出一個好的model是遠遠不夠的，我們需要加上更多可以拿來做object detection的dataset，例如COCO、ImageNet等等，可惜因為我們太晚開始，導致沒有足夠的時間來做這些龐大資料量的處理成和pascal voc相同的格式，若是可以使用這些資料，我們的model做出來應該會有更好的效果。\n",
    "\n",
    "2. Training時間不夠久\n",
    "\n",
    "前幾名的心得分享有提到他們的training時間都是以天來計算，但我們並沒有讓model訓練那麼長的時間，可能會導致他還沒收斂好就結束。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
